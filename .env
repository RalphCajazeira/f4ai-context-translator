# .env (modo ollama)
PORT=3333
DATABASE_URL=file:./data/f4.db

MT_ENABLED=true
MT_BACKEND=ollama
MT_URL=http://localhost:8001/llm-translate   # <— a URL que o branch "ollama" vai chamar

OLLAMA_URL=http://localhost:11434
# Modelo principal (focado em qualidade)
OLLAMA_MODEL=llama3.1:8b-instruct-q4_K_M
# Modelo leve para segmentos curtos
OLLAMA_LIGHT_MODEL=qwen2.5:3b-instruct
# Limites para usar o modelo leve (0 desativa cada critério)
OLLAMA_LIGHT_MAX_WORDS=4
OLLAMA_LIGHT_MAX_CHARS=40

MT_SRC=en
MT_TGT=pt-BR

TM_FUZZY_PROMOTE_MIN=0.92
TM_FUZZY_MAX_LEN_DELTA=0.10
TM_FUZZY_REQUIRE_PATCH=true

MT_LOG=1
